{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import collections, numpy\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,target):\n",
    "    df = pd.read_csv(path)\n",
    "    y = df[target]\n",
    "    X = df.drop(labels = target, axis = 1)\n",
    "    X = X.apply(pd.to_numeric)\n",
    "    return df,X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Train Dataset\n",
    "def get_train(i):\n",
    "    file = 'Data/NSL-KDD/modified/Train/Normal_Data/N' + str(i) + '.csv'\n",
    "    train_df, train_X, train_y = load_data(file,'defects')\n",
    "    y_train = []\n",
    "    for instance in train_y.values:\n",
    "        if instance == 'normal':\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(-1)\n",
    "    train_df.defects.unique()\n",
    "    return train_df,train_X,y_train\n",
    "\n",
    "#Get Test Dataset\n",
    "def get_test(i):\n",
    "    file = 'Data/NSL-KDD/modified/Train/5_anomaly/A' + str(i) + '.csv'\n",
    "    train_df, train_X, train_y = load_data(file,'defects')\n",
    "    y_train = []\n",
    "    for instance in train_y.values:\n",
    "        if instance == 'normal':\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(-1)\n",
    "    train_df.defects.unique()\n",
    "    return train_df,train_X,y_train\n",
    "\n",
    "#Divide data\n",
    "\n",
    "def divide_data(df):\n",
    "    target = 'defects'\n",
    "    y = df[target]\n",
    "    X = df.drop(labels = target, axis = 1)\n",
    "    X = X.apply(pd.to_numeric)\n",
    "    y_train = []\n",
    "    for instance in y.values:\n",
    "        if instance == 'normal':\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(-1)\n",
    "    return X,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_X, train_y):\n",
    "    clf = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "    clf.fit(train_X, train_y)\n",
    "    return clf\n",
    "\n",
    "def test_model(clf, test_X, test_y):\n",
    "    predicted = clf.predict(test_X)\n",
    "    #predict_prob = clf.predict_proba(test_X)\n",
    "    precision = metrics.precision_score(test_y,predicted,average='weighted')\n",
    "    recall = metrics.recall_score(test_y,predicted,average='weighted')\n",
    "    f1_Score = metrics.f1_score(test_y,predicted,average='weighted')\n",
    "    x = metrics.classification_report(test_y, predicted,output_dict=True)\n",
    "    print(metrics.classification_report(test_y, predicted))\n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(test_y, predict_prob[:, 1])\n",
    "    #roc_auc = metrics.auc(fpr, tpr)\n",
    "    #plt.plot(fpr, tpr, lw=1, alpha=0.3)\n",
    "    #plt.show()\n",
    "    return [precision,recall,f1_Score,x]\n",
    "\n",
    "def outlier_model(train_X,nu):\n",
    "    clf =  OneClassSVM(kernel = 'rbf',gamma = 'scale',nu=nu,shrinking= False)\n",
    "    clf.fit(train_X)\n",
    "    return clf\n",
    "\n",
    "def outlier_model_2(train_X,train_y,nn):\n",
    "    #clf =  OneClassSVM(kernel = 'sigmoid',gamma = 'scale',nu=nu,shrinking= False)\n",
    "    clf = KNeighborsClassifier(n_neighbors=10)\n",
    "    clf.fit(train_X,train_y)\n",
    "    return clf\n",
    "\n",
    "def outlier_model_3(train_X,train_y,nu):\n",
    "    #clf =  OneClassSVM(kernel = 'sigmoid',gamma = 'scale',nu=nu,shrinking= False)\n",
    "    scaler = MinMaxScaler()\n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    dist = distance_matrix(train_X,train_X)\n",
    "    print(dist)\n",
    "    clf = KNeighborsClassifier(n_neighbors=10)\n",
    "    clf.fit(train_X,train_y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Set\n",
    "df_combined = pd.DataFrame([])\n",
    "perf_score = []\n",
    "first = True\n",
    "for i in range(10):\n",
    "    print(\"Iteration :\", i)\n",
    "    Ai, Ai_X, Ai_y = get_train(i)\n",
    "    Aj, Aj_X, Aj_y = get_test(i)\n",
    "    if first:\n",
    "        df_combined = pd.concat([df_combined,Ai], ignore_index=True)\n",
    "        first = False\n",
    "    else:\n",
    "        df_combined = pd.concat([df_combined,train_df], ignore_index=True)\n",
    "    #print(\"training Classes:\",df_combined.defects.unique(),df_combined.shape)\n",
    "    X,y = divide_data(df_combined)\n",
    "    if i < 6:\n",
    "        clf = train_model(X,y)\n",
    "    train_df = Aj\n",
    "    #print(\"Testing Classes Normal:\",df_combined.defects.unique(),df_combined.shape)\n",
    "    \n",
    "    perf_score.append(test_model(clf,Ai_X, Ai_y))\n",
    "    #print(\"Testing Classes Anomaly:\",df_combined.defects.unique(),df_combined.shape)\n",
    "    perf_score.append(test_model(clf,Aj_X, Aj_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Set outlier\n",
    "df_combined = pd.DataFrame([])\n",
    "perf_score = []\n",
    "first = True\n",
    "nu = 0.4\n",
    "for i in range(10):\n",
    "    print(\"Iteration :\", i)\n",
    "    Ai, Ai_X, Ai_y = get_train(i)\n",
    "    Aj, Aj_X, Aj_y = get_test(i)\n",
    "    if first:\n",
    "        df_combined = pd.concat([df_combined,Ai], ignore_index=True)\n",
    "        first = False\n",
    "    else:\n",
    "        if n_score[2] < .8:\n",
    "            print(\"adding model\")\n",
    "            df_combined = pd.concat([df_combined,Ai], ignore_index=True)\n",
    "        if a_score[2] < .8:\n",
    "            df_combined = pd.concat([df_combined,train_df], ignore_index=True)\n",
    "    #print(\"training Classes:\",df_combined.defects.unique(),df_combined.shape)\n",
    "    X,y = divide_data(df_combined)\n",
    "    if i < 6:\n",
    "        clf = outlier_model(X, nu)\n",
    "        nu -= 0.05\n",
    "    train_df = Aj\n",
    "    print(\"+++++++++++\")\n",
    "    #print(\"Testing Classes Normal:\",df_combined.defects.unique(),df_combined.shape)\n",
    "    n_score = test_model(clf,Ai_X, Ai_y)\n",
    "    perf_score.append(n_score)\n",
    "    #print(\"Testing Classes Anomaly:\",df_combined.defects.unique(),df_combined.shape)\n",
    "    a_score = test_model(clf,Aj_X, Aj_y)\n",
    "    perf_score.append(a_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.DataFrame([])\n",
    "perf_score = []\n",
    "first = True\n",
    "for i in range(10):\n",
    "    print(\"Iteration :\", i)\n",
    "    Ai, Ai_X, Ai_y = get_train(i)\n",
    "    Aj, Aj_X, Aj_y = get_test(i)\n",
    "    if first:\n",
    "        df_combined = pd.concat([df_combined,Ai], ignore_index=True)\n",
    "        first = False\n",
    "    else:\n",
    "        if n_score[2] < .8:\n",
    "            print(\"adding model\")\n",
    "            df_combined = pd.concat([df_combined,Ai], ignore_index=True)\n",
    "        if a_score[2] < .8:\n",
    "            df_combined = pd.concat([df_combined,train_df], ignore_index=True)\n",
    "    #print(\"training Classes:\",df_combined.defects.unique(),df_combined.shape)\n",
    "    X,y = divide_data(df_combined)\n",
    "    if i < 6:\n",
    "        clf = train_model(X,y)\n",
    "    train_df = Aj\n",
    "    #print(\"Testing Classes Normal:\",df_combined.defects.unique(),df_combined.shape)\n",
    "    n_score = test_model(clf,Ai_X, Ai_y)\n",
    "    perf_score.append(n_score)\n",
    "    #print(\"Testing Classes Anomaly:\",df_combined.defects.unique(),df_combined.shape)\n",
    "    a_score = test_model(clf,Aj_X, Aj_y)\n",
    "    perf_score.append(a_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_score_df = pd.DataFrame(perf_score, columns = ['Precision',\n",
    "                                                   'Recall',\n",
    "                                                   'F1-Score','report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1 = []\n",
    "class_2 = []\n",
    "for i in range(perf_score_df.shape[0]):\n",
    "    class_1.append(perf_score_df.iloc[i,3]['1']['f1-score'])\n",
    "    class_2.append(perf_score_df.iloc[i,3]['-1']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = ['N0','A0','N1','A1','N2','A2','N3','A3','N4','A4','N5','A5','N6','A6','N7','A7','N8','A8','N9','A9']\n",
    "# style\n",
    "plt.style.use('fivethirtyeight')\n",
    " \n",
    "# create a color palette\n",
    "fig = plt.figure(num=None, figsize = (50,10))\n",
    "score = perf_score_df['F1-Score'].values\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(score,marker='', color='black', linewidth=4, alpha=0.9, label='Trained On Classes')\n",
    "plt.xlabel('Iteration', fontsize=34)\n",
    "plt.ylabel('F1-Score', fontsize=34)\n",
    "#ax.set(xlabel='Iteration', ylabel='F1-Score',fontsize = 34)\n",
    "ax.tick_params(direction='out', labelsize=34,\n",
    "               grid_color='black', grid_alpha=0.5)\n",
    "ax.set_xticks(np.arange(20))\n",
    "ax.set_xticklabels(ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = ['N0','A0','N1','A1','N2','A2','N3','A3','N4','A4','N5','A5','N6','A6','N7','A7','N8','A8','N9','A9']\n",
    "# style\n",
    "plt.style.use('fivethirtyeight')\n",
    " \n",
    "# create a color palette\n",
    "fig = plt.figure(num=None, figsize = (50,10))\n",
    "score = perf_score_df['F1-Score'].values\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(score,marker='', color='black', linewidth=4, alpha=0.9, label='Trained On Classes')\n",
    "ax.plot(class_1,marker='', color='red', linewidth=4, alpha=0.9, label='Trained On Classes')\n",
    "ax.plot(class_2,marker='', color='orange', linewidth=4, alpha=0.9, label='Trained On Classes')\n",
    "ax.legend(['weighted','Normal Class','Anomaly Class'],fontsize=20)\n",
    "plt.xlabel('Iteration', fontsize=34)\n",
    "plt.ylabel('F1-Score', fontsize=34)\n",
    "#ax.set(xlabel='Iteration', ylabel='F1-Score',fontsize = 34)\n",
    "ax.tick_params(direction='out', labelsize=34,\n",
    "               grid_color='black', grid_alpha=0.5)\n",
    "ax.set_xticks(np.arange(20))\n",
    "ax.set_xticklabels(ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
