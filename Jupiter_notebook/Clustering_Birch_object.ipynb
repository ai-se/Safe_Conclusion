{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Digraph\n",
    "import scipy.spatial.distance\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "#Clustering birch\n",
    "from freediscovery.cluster import birch_hierarchy_wrapper\n",
    "from freediscovery.cluster import Birch,BirchSubcluster\n",
    "#Sklearn\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "#Learners\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Distance measure\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcluster(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.parent = None\n",
    "        self.parent_id = None\n",
    "        self.depth = None\n",
    "        self.size = None\n",
    "        self.cluster_id = None\n",
    "        self.data_points = []\n",
    "        self.test_points = []\n",
    "        self.test_labels = []\n",
    "        self.predicted = []\n",
    "        self.centroid = None\n",
    "        self.classifier = None\n",
    "        self.outlier_model = None\n",
    "        self.cluster_obj = None\n",
    "        self.outlier_points = []\n",
    "        self.score = []\n",
    "    \n",
    "    def set_parent(self,parent_node=None):\n",
    "        if parent_node == None:\n",
    "            self.parent = None\n",
    "            self.parent_id = None\n",
    "        else:\n",
    "            self.parent = parent_node\n",
    "            self.parent_id = parent_node.cluster_id\n",
    "    \n",
    "    def set_depth(self,depth):\n",
    "        self.depth = depth\n",
    "    \n",
    "    def set_size(self,size):\n",
    "        self.size = size\n",
    "        \n",
    "    def set_cluster_id(self,cluster_id):\n",
    "        self.cluster_id = cluster_id\n",
    "        \n",
    "    def set_data_points(self,data_points):\n",
    "        self.data_points = data_points\n",
    "    \n",
    "    def set_test_labels(self,test_labels):\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "    def add_test_points(self,test_point):\n",
    "        self.test_points.append(test_point)\n",
    "        \n",
    "    def add_predicted(self,predicted):\n",
    "        self.predicted.append(predicted)\n",
    "    \n",
    "    def set_centroid(self,centroid):\n",
    "        self.centroid = centroid\n",
    "        \n",
    "    def set_classifier(self,classifier):\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def set_outlier_model(self,outlier_model):\n",
    "        self.outlier_model = outlier_model\n",
    "        \n",
    "    def set_cluster_obj(self,cluster_obj):\n",
    "        self.cluster_obj = cluster_obj\n",
    "        \n",
    "    def set_outlier_points(self,outlier_points):\n",
    "        self.outlier_points = outlier_points\n",
    "        \n",
    "    def set_score(self,score):\n",
    "        self.score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class birch(object):\n",
    "\n",
    "    def __init__(self,threshold=0.7,branching_factor=20,n_clusters=None):\n",
    "        self.threshold = threshold\n",
    "        self.branching_factor = branching_factor\n",
    "        self.n_clusters = n_clusters\n",
    "        self.Birch_clusterer = Birch(threshold=self.threshold, branching_factor=self.branching_factor,\n",
    "                                     n_clusters=self.n_clusters,compute_sample_indices=True)\n",
    "    \n",
    "    def fit(self,data,y):\n",
    "        self.data = data\n",
    "        self.y = y\n",
    "        #self.data.drop(self.data.columns[len(self.data.columns)-1], axis=1, inplace=True)\n",
    "        self.Birch_clusterer.fit(self.data)\n",
    "\n",
    "    def get_cluster_tree(self):\n",
    "        self.htree, n_clusters = birch_hierarchy_wrapper(self.Birch_clusterer)\n",
    "        clusters = {}\n",
    "        max_depth = 0\n",
    "        for i in range(n_clusters):\n",
    "            node = bcluster()\n",
    "            sub_cluster = self.htree.flatten()[i]\n",
    "            node.set_cluster_id(sub_cluster['cluster_id'])\n",
    "            depth = sub_cluster.current_depth\n",
    "            if depth > max_depth:\n",
    "                max_depth = depth\n",
    "            if i not in clusters.keys():\n",
    "                clusters[i] = {}\n",
    "            if sub_cluster.current_depth == 0:\n",
    "                node.set_parent()\n",
    "            else:\n",
    "                node.set_parent(clusters[sub_cluster.parent['cluster_id']])\n",
    "            node.set_depth(sub_cluster.current_depth)\n",
    "            node.set_size(sub_cluster['cluster_size'])\n",
    "            node.set_data_points(sub_cluster['document_id_accumulated'])\n",
    "            centroid = self.data.iloc[sub_cluster['document_id_accumulated'], :].mean(axis=0).values\n",
    "            node.set_centroid(centroid)\n",
    "            clusters[i] = node\n",
    "        return clusters,max_depth\n",
    "    \n",
    "    def show_clutser_tree(self):\n",
    "        self.htree.display_tree()\n",
    "        \n",
    "    def model_adder(self,cluster_tree):\n",
    "        for cluster_id in cluster_tree:\n",
    "            clf = DecisionTreeClassifier(criterion='entropy')\n",
    "            sample_points = cluster_tree[cluster_id].data_points\n",
    "            train_X_sub = self.data.iloc[sample_points,:]\n",
    "            train_y_sub = self.y.iloc[sample_points]\n",
    "            clf.fit(train_X_sub,train_y_sub)\n",
    "            cluster_tree[cluster_id].set_classifier(clf)\n",
    "        return cluster_tree\n",
    "        \n",
    "    def predict(self,test_X,depth):\n",
    "        predicted = []\n",
    "        for test_instance in test_X.iterrows():\n",
    "            test_sample = test_instance[1].values\n",
    "            min_distance = float('inf')\n",
    "            selected_cluster = None\n",
    "            for cluster_id in cluster_tree:\n",
    "                if cluster_tree[cluster_id].depth != depth:\n",
    "                    continue\n",
    "                u = cluster_tree[cluster_id].centroid\n",
    "                v = np.asarray(test_sample,dtype='float64')\n",
    "                distance = euclidean(u,v)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    selected_cluster = cluster_id\n",
    "            cluster_tree[selected_cluster].add_test_points(test_instance[0])\n",
    "            _predicted_label = cluster_tree[selected_cluster].classifier.predict([test_sample])\n",
    "            cluster_tree[selected_cluster].add_predicted(_predicted_label)\n",
    "            predicted.append(_predicted_label)\n",
    "        return predicted\n",
    "    \n",
    "    def certify_model(self,cluster_tree,test_y):\n",
    "        for cluster_id in cluster_tree:\n",
    "            if len(cluster_tree[cluster_id].test_points) == 0:\n",
    "                continue\n",
    "            cluster_tree[cluster_id].set_test_labels(test_y[cluster_tree[cluster_id].test_points].values)\n",
    "            score = metrics.classification_report(cluster_tree[cluster_id].test_labels, cluster_tree[cluster_id].predicted)\n",
    "            cluster_tree[cluster_id].set_score(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,target):\n",
    "    df = pd.read_csv(path)\n",
    "    if path == 'data/jm1.csv':\n",
    "        df = df[~df.uniq_Op.str.contains(\"\\?\")]\n",
    "    y = df[target]\n",
    "    X = df.drop(labels = target, axis = 1)\n",
    "    X = X.apply(pd.to_numeric)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    return train_X, test_X, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Driver\n",
    "def cluster_driver(file,print_tree = False):\n",
    "    train_X, test_X, train_y, test_y = load_data(file,'defects')\n",
    "    cluster = birch(branching_factor=20)\n",
    "    cluster.fit(train_X,train_y)\n",
    "    cluster_tree,max_depth = cluster.get_cluster_tree()\n",
    "    cluster_tree = cluster.model_adder(cluster_tree)\n",
    "    if print_tree:\n",
    "        cluster.show_clutser_tree()\n",
    "    return cluster,cluster_tree,max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the cluster tree\n",
    "file = 'data/JDT.csv'\n",
    "cluster,cluster_tree,max_depth = cluster_driver(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.88      0.87       258\n",
      "        True       0.53      0.49      0.51        72\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       330\n",
      "   macro avg       0.70      0.68      0.69       330\n",
      "weighted avg       0.79      0.79      0.79       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base performance score\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "train_X, test_X, train_y, test_y = load_data(file,'defects')\n",
    "clf.fit(train_X, train_y)\n",
    "predicted = clf.predict(test_X)\n",
    "print(metrics.classification_report(test_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mutated_data(path,target):\n",
    "    train_X, test_X, train_y, test_y = load_data(path,target)\n",
    "    test_X = pd.concat([train_X,test_X])\n",
    "    test_y = pd.concat([train_y,test_y])\n",
    "    return test_X,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.59      0.68       254\n",
      "        True       0.27      0.50      0.35        76\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       330\n",
      "   macro avg       0.53      0.54      0.51       330\n",
      "weighted avg       0.67      0.57      0.60       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Birch classifier score(mention depth)\n",
    "file = 'data/JDT_1.csv'\n",
    "test_X,test_y = load_mutated_data(file,'defects')\n",
    "depth = max_depth\n",
    "predicted = cluster.predict(test_X,depth)\n",
    "print(metrics.classification_report(test_y, predicted))\n",
    "cluster.certify_model(cluster_tree,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00        34\n",
      "        True       0.13      1.00      0.23         5\n",
      "\n",
      "   micro avg       0.13      0.13      0.13        39\n",
      "   macro avg       0.06      0.50      0.11        39\n",
      "weighted avg       0.02      0.13      0.03        39\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.67      0.73         6\n",
      "        True       0.71      0.83      0.77         6\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.65      0.69        17\n",
      "        True       0.50      0.60      0.55        10\n",
      "\n",
      "   micro avg       0.63      0.63      0.63        27\n",
      "   macro avg       0.62      0.62      0.62        27\n",
      "weighted avg       0.65      0.63      0.63        27\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.30      0.37        10\n",
      "        True       0.30      0.50      0.37         6\n",
      "\n",
      "   micro avg       0.38      0.38      0.38        16\n",
      "   macro avg       0.40      0.40      0.37        16\n",
      "weighted avg       0.42      0.38      0.37        16\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.50      0.62        16\n",
      "        True       0.11      0.33      0.17         3\n",
      "\n",
      "   micro avg       0.47      0.47      0.47        19\n",
      "   macro avg       0.46      0.42      0.39        19\n",
      "weighted avg       0.69      0.47      0.54        19\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.52      0.65        21\n",
      "        True       0.55      0.86      0.67        14\n",
      "\n",
      "   micro avg       0.66      0.66      0.66        35\n",
      "   macro avg       0.70      0.69      0.66        35\n",
      "weighted avg       0.73      0.66      0.65        35\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.36      0.50        11\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.33      0.33      0.33        12\n",
      "   macro avg       0.40      0.18      0.25        12\n",
      "weighted avg       0.73      0.33      0.46        12\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      1.00      0.75         3\n",
      "        True       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.60      0.60      0.60         5\n",
      "   macro avg       0.30      0.50      0.37         5\n",
      "weighted avg       0.36      0.60      0.45         5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      1.00      0.89         4\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.80      0.80      0.80         5\n",
      "   macro avg       0.40      0.50      0.44         5\n",
      "weighted avg       0.64      0.80      0.71         5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.76      0.87        17\n",
      "        True       0.20      1.00      0.33         1\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        18\n",
      "   macro avg       0.60      0.88      0.60        18\n",
      "weighted avg       0.96      0.78      0.84        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      1.00      0.80         8\n",
      "        True       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        12\n",
      "   macro avg       0.33      0.50      0.40        12\n",
      "weighted avg       0.44      0.67      0.53        12\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      1.00      0.93         7\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.88      0.88      0.88         8\n",
      "   macro avg       0.44      0.50      0.47         8\n",
      "weighted avg       0.77      0.88      0.82         8\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.89      0.73         9\n",
      "        True       0.67      0.29      0.40         7\n",
      "\n",
      "   micro avg       0.62      0.62      0.62        16\n",
      "   macro avg       0.64      0.59      0.56        16\n",
      "weighted avg       0.64      0.62      0.58        16\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.83      0.77        12\n",
      "        True       0.33      0.20      0.25         5\n",
      "\n",
      "   micro avg       0.65      0.65      0.65        17\n",
      "   macro avg       0.52      0.52      0.51        17\n",
      "weighted avg       0.60      0.65      0.62        17\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.43      0.60         7\n",
      "        True       0.33      1.00      0.50         2\n",
      "\n",
      "   micro avg       0.56      0.56      0.56         9\n",
      "   macro avg       0.67      0.71      0.55         9\n",
      "weighted avg       0.85      0.56      0.58         9\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67         2\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.25      0.33         2\n",
      "weighted avg       1.00      0.50      0.67         2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.33      0.50      0.40         2\n",
      "        True       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.25      0.25      0.25         4\n",
      "   macro avg       0.17      0.25      0.20         4\n",
      "weighted avg       0.17      0.25      0.20         4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67         2\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.25      0.33         2\n",
      "weighted avg       1.00      0.50      0.67         2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.67      0.80         3\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.67      0.67      0.67         3\n",
      "   macro avg       0.50      0.33      0.40         3\n",
      "weighted avg       1.00      0.67      0.80         3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91         5\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.83      0.83      0.83         6\n",
      "   macro avg       0.42      0.50      0.45         6\n",
      "weighted avg       0.69      0.83      0.76         6\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.60      0.67         5\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         6\n",
      "   macro avg       0.38      0.30      0.33         6\n",
      "weighted avg       0.62      0.50      0.56         6\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.40      0.57         5\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.40      0.40      0.40         5\n",
      "   macro avg       0.50      0.20      0.29         5\n",
      "weighted avg       1.00      0.40      0.57         5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      1.00      0.95         9\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.90      0.90      0.90        10\n",
      "   macro avg       0.45      0.50      0.47        10\n",
      "weighted avg       0.81      0.90      0.85        10\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      1.00      0.67         1\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      1.00      0.86         3\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.38      0.50      0.43         4\n",
      "weighted avg       0.56      0.75      0.64         4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67         2\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.25      0.33         2\n",
      "weighted avg       1.00      0.50      0.67         2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00         5\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00         5\n",
      "   macro avg       0.00      0.00      0.00         5\n",
      "weighted avg       0.00      0.00      0.00         5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.50      0.67         4\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         4\n",
      "   macro avg       0.50      0.25      0.33         4\n",
      "weighted avg       1.00      0.50      0.67         4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.57      0.67         7\n",
      "        True       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         8\n",
      "   macro avg       0.40      0.29      0.33         8\n",
      "weighted avg       0.70      0.50      0.58         8\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in cluster_tree:\n",
    "    if len(cluster_tree[i].test_points) == 0:\n",
    "        continue\n",
    "    print(cluster_tree[i].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
